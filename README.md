# TalkWithDoc-Frontend
# TalkWithDoc: Retrieval-Augmented Generation (RAG) Implementation with Large Language Models (LLMs)

## Overview
TalkWithDoc is a project aimed at enabling users to interact with web content through a conversational interface powered by Retrieval-Augmented Generation (RAG) and Large Language Models (LLMs). The project utilizes cutting-edge technologies to crawl data from web pages, convert it into vectorized format, and then employ a Mixtral 8x7b LLM model via Groq API to generate responses to user queries.

## Features
- Web scraping: Extracts relevant text data from user-provided web links.
- Data preprocessing: Stores crawled data in a text file for vectorization.
- Vectorization: Converts text data into vectorized format suitable for LLM input.
- LLM Integration: Utilizes the MixtR8 8x7b model via Groq API for response generation.
- Conversational interface: Allows users to interact with web content through a chatbot interface.
# Getting Started with Create React App

This project was bootstrapped with [Create React App](https://github.com/facebook/create-react-app).

## Available Scripts

In the project directory, you can run:

### `npm start`

Runs the app in the development mode.\
Open [http://localhost:3000](http://localhost:3000) to view it in your browser.

The page will reload when you make changes.\
You may also see any lint errors in the console.
